# Mnemonics

### An intelligent, local-first engine for cognitive retention.

Mnemonics is a high-performance utility designed to bridge the gap between complex academic data and long-term neural encoding. By leveraging local Small Language Models (SLMs), the platform architects structured memory anchorsâ€”transforming raw information into recall-optimized hooks with zero latency and absolute privacy.

---

## ðŸ”¬ Core Philosophy

Traditional study methods often struggle with high-density information. Mnemonics automates the creation of phonetically stable and semantically resonant memory aids, allowing students to focus on mastery rather than rote memorization.

## âš¡ Key Features

* **Privacy-Centric Inference:** Powered by Ollama, ensuring all data remains on your local hardware.
* **Dual-Engine Logic:** Seamlessly toggle between Acronym (lexical compression) and Acrostic (narrative expansion) modes.
* **Adaptive Tone:** Fine-tune generation for Academic, Absurd, or Visceral styles to maximize mnemonic "stickiness."
* **Minimalist Workflow:** A friction-free interface designed for high-output study sessions.

## ðŸ›  Tech Stack

- **Framework:** Next.js 15 (App Router)
- **Styling:** Tailwind CSS
- **Icons:** Lucide-React
- **AI Engine:** Ollama (Recommended: llama3.2:1b)

## ðŸš€ Getting Started

### Prerequisites
* Ollama installed and running.
* Node.js 18.x or higher.

### Installation

1. **Clone the repository:**
   git clone https://github.com/your-username/mnemonics.git

2. **Install dependencies:**
   npm install

3. **Pull the inference model:**
   ollama pull llama3.2:1b

4. **Launch the development server:**
   npm run dev

## ðŸ“œ License
Distributed under the MIT License.
